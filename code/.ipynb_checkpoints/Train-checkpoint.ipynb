{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font size=\"7\"><b>Training</b></font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will focus on the choice of correct model for training and its preparation. Multiple models have been downloaded and are stored in models/pre-trained directory. All of the models were tested and below markdown comments will focus only on the model that was chosen as the best performing one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>1. Import modules required for this notebook</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from shutil import rmtree\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>2. Get paths for directories that will be used further in the code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not run this again if you run any of the \"cd\" commands later in the notebook because you will overwrite your home directory path\n",
    "cur_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = os.path.dirname(cur_dir)\n",
    "work_dir = os.path.join(main_dir, \"public/Birds\")\n",
    "scripts_dir = os.path.join(main_dir, \"scripts\")\n",
    "models_dir = os.path.join(main_dir, \"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>3. Download model from tensorflow and set a variable that will store a path to the chosen model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/michal/MSc_lin/7144COMP/Coursework_2/models\n",
      "/home/michal/MSc_lin/7144COMP/Coursework_2/models/pre-trained\n"
     ]
    }
   ],
   "source": [
    "%cd $models_dir\n",
    "pretrained_dir = os.path.join(models_dir, \"pre-trained\")\n",
    "model_path = os.path.join(models_dir, model_name)\n",
    "arch = model_name + \".tar.gz\"\n",
    "tf_url = \"http://download.tensorflow.org/models/object_detection/tf2/20200711\"\n",
    "# Clean directory if exists\n",
    "if os.path.isdir(model_path):\n",
    "    rmtree(model_path)\n",
    "%cd $pretrained_dir\n",
    "# Download and unpack the model basic configuration files\n",
    "if arch not in os.listdir(pretrained_dir):\n",
    "    download_model = os.path.join(tf_url, model_name + \".tar.gz\")\n",
    "    !wget $download_model\n",
    "tar = tarfile.open(arch, \"r:gz\")\n",
    "tar.extractall(models_dir)\n",
    "tar.close()\n",
    "\n",
    "# Clean directory by removing saved model and renaming pretrained checkpoint directory as \"checkpoint\" is reserved for the file\n",
    "os.rename(os.path.join(model_path, \"checkpoint\"), os.path.join(model_path, \"pre-checkpoint\"))\n",
    "rmtree(os.path.join(model_path, \"saved_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>4. Edit model's hyperparameters</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>4.1 Set hyperparameters</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All four classes are being used thus number of classes is set to 4. \n",
    "#### Batch size for both training and evaluation is set to 1 due to current hardware restrictions as GPU and CPU cannot handle higher number of batches. If training is performed on better configuration this value can be increased.\n",
    "#### Number of training steps is set to 30000 as this setting provides the best training results and avoids overfitting of the model.\n",
    "#### Learning rate of .0007 proved to be the best setting where training is being done in resonable time and overfitting does not occur.\n",
    "#### To avoid early overfitting warmup learning rate is set to .00004.\n",
    "#### It was concluded that 10% of total steps should be reserved as warmup steps for a good smooth start of the training.\n",
    "#### Path to the last pre-trained checkpoint is set as well as the type is changed to detection.\n",
    "#### Other hyperparameters involve path changes for label map, train and test TFrecords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "batch_size = 1\n",
    "num_steps = 25000\n",
    "learning_rate_base = \".0007\"\n",
    "total_steps = 25000\n",
    "warmup_learning_rate = \".00004\"\n",
    "warmup_steps = 2500\n",
    "checkpoint_path = os.path.join(model_path, \"pre-checkpoint\", \"ckpt-0\")\n",
    "fine_tune_checkpoint_type = \"detection\"\n",
    "label_map_path = os.path.join(work_dir, \"label_map.pbtxt\")\n",
    "train_input_path = os.path.join(work_dir, \"train.record\")\n",
    "eval_input_path = os.path.join(work_dir, \"test.record\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>4.2 Apply changes</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/michal/MSc_lin/7144COMP/Coursework_2/models/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8\n"
     ]
    }
   ],
   "source": [
    "%cd $model_path\n",
    "with open('pipeline.config') as f:\n",
    "    file = f.read()\n",
    "with open('pipeline.config', 'w') as f:\n",
    "    # Set number of classes num_classes\n",
    "    file = re.sub('num_classes: [0-9]+', 'num_classes: {}'.format(num_classes), file)\n",
    "    \n",
    "    # Set train and eval batch size\n",
    "    file = re.sub('batch_size: [0-9]+', 'batch_size: {}'.format(batch_size), file)\n",
    "    \n",
    "    # Set number of training steps\n",
    "    file = re.sub('num_steps: [0-9]+', 'num_steps: {}'.format(num_steps), file)\n",
    "    \n",
    "    # Set base learning rate\n",
    "    file = re.sub('learning_rate_base: .[0-9]+', 'learning_rate_base: {}'.format(learning_rate_base), file)\n",
    "    \n",
    "    # Set total number of steps\n",
    "    file = re.sub('total_steps: [0-9]+', 'total_steps: {}'.format(total_steps), file)\n",
    "    \n",
    "    # Set warmup learning rate\n",
    "    file = re.sub('warmup_learning_rate: .[0-9]+', 'warmup_learning_rate: {}'.format(warmup_learning_rate), file)\n",
    "    \n",
    "    # Set number of warmup steps\n",
    "    file = re.sub('warmup_steps: [0-9]+', 'warmup_steps: {}'.format(warmup_steps), file)\n",
    "    \n",
    "    # Set path to the pre trained checkpoint\n",
    "    file = re.sub('fine_tune_checkpoint: \".*?\"', 'fine_tune_checkpoint: \"{}\"'.format(checkpoint_path), file)\n",
    "    \n",
    "    # Set type of the checkpoint\n",
    "    file = re.sub('fine_tune_checkpoint_type: \".*?\"', 'fine_tune_checkpoint_type: \"{}\"'.format(fine_tune_checkpoint_type), file)\n",
    "    \n",
    "    # Set path to the label map file\n",
    "    file = re.sub('label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_path), file)\n",
    "    \n",
    "    # Set path to the train TFrecord file\n",
    "    file = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_input_path), file)\n",
    "    \n",
    "    # Set path to the test TFrecord file\n",
    "    file = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(eval_input_path), file)\n",
    "    \n",
    "    f.write(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>4.3 Show model configuration</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Faster R-CNN with Resnet-50 (v1)\n",
      "# Trained on COCO, initialized from Imagenet classification checkpoint\n",
      "\n",
      "# This config is TPU compatible.\n",
      "\n",
      "model {\n",
      "  faster_rcnn {\n",
      "    num_classes: 4\n",
      "    image_resizer {\n",
      "      fixed_shape_resizer {\n",
      "        width: 1024\n",
      "        height: 1024\n",
      "      }\n",
      "    }\n",
      "    feature_extractor {\n",
      "      type: 'faster_rcnn_resnet101_keras'\n",
      "      batch_norm_trainable: true\n",
      "    }\n",
      "    first_stage_anchor_generator {\n",
      "      grid_anchor_generator {\n",
      "        scales: [0.25, 0.5, 1.0, 2.0]\n",
      "        aspect_ratios: [0.5, 1.0, 2.0]\n",
      "        height_stride: 16\n",
      "        width_stride: 16\n",
      "      }\n",
      "    }\n",
      "    first_stage_box_predictor_conv_hyperparams {\n",
      "      op: CONV\n",
      "      regularizer {\n",
      "        l2_regularizer {\n",
      "          weight: 0.0\n",
      "        }\n",
      "      }\n",
      "      initializer {\n",
      "        truncated_normal_initializer {\n",
      "          stddev: 0.01\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    first_stage_nms_score_threshold: 0.0\n",
      "    first_stage_nms_iou_threshold: 0.7\n",
      "    first_stage_max_proposals: 300\n",
      "    first_stage_localization_loss_weight: 2.0\n",
      "    first_stage_objectness_loss_weight: 1.0\n",
      "    initial_crop_size: 14\n",
      "    maxpool_kernel_size: 2\n",
      "    maxpool_stride: 2\n",
      "    second_stage_box_predictor {\n",
      "      mask_rcnn_box_predictor {\n",
      "        use_dropout: false\n",
      "        dropout_keep_probability: 1.0\n",
      "        fc_hyperparams {\n",
      "          op: FC\n",
      "          regularizer {\n",
      "            l2_regularizer {\n",
      "              weight: 0.0\n",
      "            }\n",
      "          }\n",
      "          initializer {\n",
      "            variance_scaling_initializer {\n",
      "              factor: 1.0\n",
      "              uniform: true\n",
      "              mode: FAN_AVG\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        share_box_across_classes: true\n",
      "      }\n",
      "    }\n",
      "    second_stage_post_processing {\n",
      "      batch_non_max_suppression {\n",
      "        score_threshold: 0.0\n",
      "        iou_threshold: 0.6\n",
      "        max_detections_per_class: 100\n",
      "        max_total_detections: 300\n",
      "      }\n",
      "      score_converter: SOFTMAX\n",
      "    }\n",
      "    second_stage_localization_loss_weight: 2.0\n",
      "    second_stage_classification_loss_weight: 1.0\n",
      "    use_static_shapes: true\n",
      "    use_matmul_crop_and_resize: true\n",
      "    clip_anchors_to_image: true\n",
      "    use_static_balanced_label_sampler: true\n",
      "    use_matmul_gather_in_matcher: true\n",
      "  }\n",
      "}\n",
      "\n",
      "train_config: {\n",
      "  batch_size: 1\n",
      "  sync_replicas: true\n",
      "  startup_delay_steps: 0\n",
      "  replicas_to_aggregate: 8\n",
      "  num_steps: 30000\n",
      "  optimizer {\n",
      "    momentum_optimizer: {\n",
      "      learning_rate: {\n",
      "        cosine_decay_learning_rate {\n",
      "          learning_rate_base: .0007\n",
      "          total_steps: 30000\n",
      "          warmup_learning_rate: .00004\n",
      "          warmup_steps: 3000\n",
      "        }\n",
      "      }\n",
      "      momentum_optimizer_value: 0.9\n",
      "    }\n",
      "    use_moving_average: false\n",
      "  }\n",
      "  fine_tune_checkpoint_version: V2\n",
      "  fine_tune_checkpoint: \"/home/michal/MSc_lin/7144COMP/Coursework_2/models/pre-checkpoint/ckpt-0\"\n",
      "  fine_tune_checkpoint_type: \"detection\"\n",
      "  data_augmentation_options {\n",
      "    random_horizontal_flip {\n",
      "    }\n",
      "  }\n",
      "\n",
      "  data_augmentation_options {\n",
      "    random_adjust_hue {\n",
      "    }\n",
      "  }\n",
      "\n",
      "  data_augmentation_options {\n",
      "    random_adjust_contrast {\n",
      "    }\n",
      "  }\n",
      "\n",
      "  data_augmentation_options {\n",
      "    random_adjust_saturation {\n",
      "    }\n",
      "  }\n",
      "\n",
      "  data_augmentation_options {\n",
      "     random_square_crop_by_scale {\n",
      "      scale_min: 0.6\n",
      "      scale_max: 1.3\n",
      "    }\n",
      "  }\n",
      "  max_number_of_boxes: 100\n",
      "  unpad_groundtruth_tensors: false\n",
      "  use_bfloat16: true  # works only on TPUs\n",
      "}\n",
      "train_input_reader: {\n",
      "  label_map_path: \"/home/michal/MSc_lin/7144COMP/Coursework_2/public/Birds/label_map.pbtxt\"\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/home/michal/MSc_lin/7144COMP/Coursework_2/public/Birds/train.record\"\n",
      "  }\n",
      "}\n",
      "\n",
      "eval_config: {\n",
      "  metrics_set: \"coco_detection_metrics\"\n",
      "  use_moving_averages: false\n",
      "  batch_size: 1;\n",
      "}\n",
      "\n",
      "eval_input_reader: {\n",
      "  label_map_path: \"/home/michal/MSc_lin/7144COMP/Coursework_2/public/Birds/label_map.pbtxt\"\n",
      "  shuffle: false\n",
      "  num_epochs: 1\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/home/michal/MSc_lin/7144COMP/Coursework_2/public/Birds/test.record\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%cat $model_path/pipeline.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>5. Initiate training</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/michal/MSc_lin/7144COMP/Coursework_2/scripts\n",
      "2020-12-08 19:31:47.958292: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-12-08 19:31:49.459396: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2020-12-08 19:31:49.484239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-12-08 19:31:49.484590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:1c:00.0 name: GeForce RTX 2080 computeCapability: 7.5\n",
      "coreClock: 1.86GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.23GiB/s\n",
      "2020-12-08 19:31:49.484622: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-12-08 19:31:49.486232: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2020-12-08 19:31:49.487912: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2020-12-08 19:31:49.488303: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2020-12-08 19:31:49.490027: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-12-08 19:31:49.490929: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-12-08 19:31:49.494014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-12-08 19:31:49.494204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-12-08 19:31:49.494544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-12-08 19:31:49.494786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2020-12-08 19:31:49.495138: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-08 19:31:49.500931: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 4149915000 Hz\n",
      "2020-12-08 19:31:49.501326: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558cad4f7fa0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-08 19:31:49.501340: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-12-08 19:31:49.507483: W tensorflow/compiler/xla/service/platform_util.cc:210] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 8366784512\n",
      "2020-12-08 19:31:49.507611: I tensorflow/compiler/jit/xla_gpu_device.cc:161] Ignoring visible XLA_GPU_JIT device. Device number is 0, reason: Internal: no supported devices found for platform CUDA\n",
      "2020-12-08 19:31:49.507797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-12-08 19:31:49.508028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:1c:00.0 name: GeForce RTX 2080 computeCapability: 7.5\n",
      "coreClock: 1.86GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.23GiB/s\n",
      "2020-12-08 19:31:49.508056: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-12-08 19:31:49.508095: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2020-12-08 19:31:49.508109: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2020-12-08 19:31:49.508121: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2020-12-08 19:31:49.508133: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-12-08 19:31:49.508145: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-12-08 19:31:49.508157: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-12-08 19:31:49.508207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-12-08 19:31:49.508434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-12-08 19:31:49.508637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2020-12-08 19:31:49.508660: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "Traceback (most recent call last):\n",
      "  File \"model_main_tf2.py\", line 113, in <module>\n",
      "    tf.compat.v1.app.run()\n",
      "  File \"/home/michal/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/home/michal/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/absl/app.py\", line 303, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/michal/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/absl/app.py\", line 251, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"model_main_tf2.py\", line 101, in main\n",
      "    strategy = tf.compat.v2.distribute.MirroredStrategy()\n",
      "  File \"/home/michal/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 268, in __init__\n",
      "    extended = MirroredExtended(\n",
      "  File \"/home/michal/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 306, in __init__\n",
      "    devices = devices or all_local_devices()\n",
      "  File \"/home/michal/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 172, in all_local_devices\n",
      "    devices = config.list_logical_devices(\"GPU\")\n",
      "  File \"/home/michal/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/framework/config.py\", line 403, in list_logical_devices\n",
      "    return context.context().list_logical_devices(device_type=device_type)\n",
      "  File \"/home/michal/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/eager/context.py\", line 1344, in list_logical_devices\n",
      "    self.ensure_initialized()\n",
      "  File \"/home/michal/anaconda3/envs/Object-Detection-API/lib/python3.8/site-packages/tensorflow/python/eager/context.py\", line 539, in ensure_initialized\n",
      "    context_handle = pywrap_tfe.TFE_NewContext(opts)\n",
      "tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory\n"
     ]
    }
   ],
   "source": [
    "%cd $scripts_dir\n",
    "!python model_main_tf2.py --model_dir=$model_path --pipeline_config_path=$model_path/pipeline.config --num_train_steps=$num_steps --alsologtostderr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Env-7144COMP",
   "language": "python",
   "name": "env-7144comp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
